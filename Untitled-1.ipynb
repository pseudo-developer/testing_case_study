{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession with Delta Lake support\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Test\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.3\n"
     ]
    }
   ],
   "source": [
    "print(spark.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+--------------------+------------+\n",
      "|CRASH_ID|UNIT_NBR|PRSN_NBR|              CHARGE|CITATION_NBR|\n",
      "+--------+--------+--------+--------------------+------------+\n",
      "|14768622|       1|       1|DRIVING WHILE INT...|        NULL|\n",
      "|14838637|       1|       1|                 DWI|  1600000015|\n",
      "|14838641|       1|       1|RAN RED LIGHT SOL...|      L20440|\n",
      "|14838641|       2|       1|NO DRIVER'S LICEN...|      L23141|\n",
      "|14838668|       1|       1|DRIVING WHILE INT...|TX4IC50SRJD3|\n",
      "+--------+--------+--------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+--------+--------+--------------------+------------+--------------+\n",
      "|CRASH_ID|UNIT_NBR|PRSN_NBR|              CHARGE|CITATION_NBR|current_date()|\n",
      "+--------+--------+--------+--------------------+------------+--------------+\n",
      "|14768622|       1|       1|DRIVING WHILE INT...|        NULL|    2024-11-28|\n",
      "|14838637|       1|       1|                 DWI|  1600000015|    2024-11-28|\n",
      "|14838641|       1|       1|RAN RED LIGHT SOL...|      L20440|    2024-11-28|\n",
      "|14838641|       2|       1|NO DRIVER'S LICEN...|      L23141|    2024-11-28|\n",
      "|14838668|       1|       1|DRIVING WHILE INT...|TX4IC50SRJD3|    2024-11-28|\n",
      "|14838669|       2|       1|     DWI W/BAC >.015| 2015-000006|    2024-11-28|\n",
      "|14838670|       1|       1|DRIVING WHILE INT...| 2016-000003|    2024-11-28|\n",
      "|14838685|       1|       1|FAILED TO DRIVE S...|   138434825|    2024-11-28|\n",
      "|14838693|       1|       1|DRIVING WHILE INT...|TX4IC60UKQND|    2024-11-28|\n",
      "|14838768|       2|       1|                 DWI|        NULL|    2024-11-28|\n",
      "|14838834|       1|       1|  NO DRIVERS LICENSE|    10019200|    2024-11-28|\n",
      "|14838834|       1|       1|FAIL TO CONTROL S...|    10019200|    2024-11-28|\n",
      "|14838834|       1|       1|   LEAVING THE SCENE|    10019200|    2024-11-28|\n",
      "|14838841|       1|       1|       FTLI   / DWLI|    16-43861|    2024-11-28|\n",
      "|14838841|       1|       1|LEAVING SCENE OF ...|    16-43861|    2024-11-28|\n",
      "|14838841|       1|       1|FAIL TO DRIVE IN ...|    16-43861|    2024-11-28|\n",
      "|14838841|       1|       1|FAIL TO REPORT AC...|    16-43861|    2024-11-28|\n",
      "|14838842|       1|       1|LEAVING SCENE OF ...|    16-43859|    2024-11-28|\n",
      "|14838842|       1|       1|FAIL TO REPORT AC...|    16-43859|    2024-11-28|\n",
      "|14838842|       1|       1|FAIL TO DRIVE IN ...|    16-43859|    2024-11-28|\n",
      "+--------+--------+--------+--------------------+------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option('header', True)\n",
    "    .load(r\"C:\\Users\\Ankit\\Desktop\\try_env\\myenv\\project_files\\raw_data\\Charges_use.csv\")\n",
    ")\n",
    "# df1 = spark.read.format(\"csv\").option('header', True).load(\"C:\\\\Users\\\\kumar.ankit2\\\\Desktop\\\\Charges_use.csv\")\n",
    "\n",
    "df.show(5)\n",
    "\n",
    "df.createOrReplaceTempView('ankit')\n",
    "spark.sql(\"select *, current_date() from ankit\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
